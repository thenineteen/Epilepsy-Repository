{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as npx\n",
    "import itertools\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XmlRecord:\n",
    "    def __init__(self, fileLocation, surgicalPatients=None, maxHospitalNumbers=None):\n",
    "        \"\"\"\n",
    "        Initialises an object for an XML file, storing the information extracted from the XML\n",
    "        If surgicalPatients and maxHospitalNumbers are given, look up the record in the surgical DB\n",
    "        and add operation details to the object\n",
    "        \"\"\"\n",
    "        self._fileLocation = fileLocation\n",
    "        self._caseElement = ET.parse(self._fileLocation).getroot()\n",
    "        \n",
    "        self._meetingElement= self._caseElement.find('meeting')\n",
    "        self._demographicsElement = self._caseElement.find('demographics')\n",
    "        self._eventsElement = self._caseElement.find('events')\n",
    "        MRN = self._demographicsElement.find('identifier').text\n",
    "        \n",
    "        self._dataDict = {\n",
    "            \"MRN1\": MRN,\n",
    "            \"MRN2\": None,\n",
    "            \"MRN3\": None,\n",
    "            \"MRN4\": None,\n",
    "            \"IDP\": None, #CHECK THIS!\n",
    "        }\n",
    "        \n",
    "        self._eventCount = int(self._eventsElement.find('count').text)\n",
    "        self._rawClassificationArray = self.extractRawClassificationArray()\n",
    "        \n",
    "        self.lookUpSurgicalResult(surgicalPatients, maxHospitalNumbers)\n",
    "        self._hippocampalSclerosis = self.extractHippocampalSclerosis(self._fileLocation)\n",
    "            \n",
    "    def extractRawClassificationArray(self):\n",
    "        rawClassificationArray = []\n",
    "        for nthEvent, event in zip(range(self._eventCount), self._eventsElement):\n",
    "            eventClassificationArray = []\n",
    "            eventClassificationLength = int(event.find('classificationLength').text)\n",
    "            for nthClassification, classification in zip(range(eventClassificationLength), event):\n",
    "                eventClassificationArray.append(classification.text)\n",
    "            rawClassificationArray.append(eventClassificationArray)\n",
    "        return rawClassificationArray\n",
    "    \n",
    "    def RawClassificationToChecklists(self, rawClassificationArray=None):\n",
    "        if not rawClassificationArray:\n",
    "            rawClassificationArray = self._rawClassificationArray\n",
    "        flattenedList = list((itertools.chain(*rawClassificationArray)))\n",
    "#         numberOfFeatures = len(pdfToMatlabToMLTranslation['pdf'])\n",
    "        pdfFeatureDict = dict(zip(pdfToMatlabToMLTranslation['pdf'], np.zeros(1000).astype(bool)))\n",
    "        mlFeatureDict = dict(zip(mlLabels, np.zeros(1000).astype(bool)))\n",
    "        \n",
    "        stepsFound = []\n",
    "        stepsNotFound = []\n",
    "        stepsFoundByRegex = []\n",
    "        asAboveFound = []\n",
    "        \n",
    "        for classificationStep in flattenedList:\n",
    "            found = False\n",
    "            if classificationStep:\n",
    "                for pdfLabel in pdfToMatlabToMLTranslation['pdf']:\n",
    "                    if pdfLabel.lower() == classificationStep.lower() or pdfLabel.lower() == stripClassificationStep(classificationStep):\n",
    "                        pdfFeatureDict[pdfLabel] = True\n",
    "                        mlLabelFound = pdfToMatlabToMLTranslation[pdfToMatlabToMLTranslation['pdf'] == pdfLabel]['ml'].values[0]\n",
    "                        mlFeatureDict[mlLabelFound] = True\n",
    "                        found = True\n",
    "                        stepsFound.append(classificationStep)\n",
    "                if not found:\n",
    "                    keysFound = regexYamlMatch(semiologyRegexDict, classificationStep)\n",
    "                    if keysFound:\n",
    "                        stepsFoundByRegex.append([keysFound, classificationStep])\n",
    "                        for keyFound in keysFound:\n",
    "                            mlFeatureDict[keyFound] = True\n",
    "                        found = True\n",
    "                if 'as above' in stripClassificationStep(classificationStep):\n",
    "                    found = True\n",
    "                    stepsFound.append(classificationStep)\n",
    "                if not found:\n",
    "                    stepsNotFound.append(classificationStep)\n",
    "        \n",
    "        stepsFoundByRegex = [i for i in stepsFoundByRegex if i]\n",
    "        self._pdfFeatureDict = pdfFeatureDict\n",
    "        self._mlFeatureDict = mlFeatureDict\n",
    "        self._stepsFound = stepsFound\n",
    "        self._stepsNotFound = stepsNotFound\n",
    "        self._stepsFoundByRegex = stepsFoundByRegex\n",
    "        self._asAboveFound = asAboveFound\n",
    "            \n",
    "        return {'pdfFeatureDict': pdfFeatureDict,\n",
    "                'mlFeatureDict': mlFeatureDict, \n",
    "                'stepsFound': stepsFound,\n",
    "                'stepsNotFound': stepsNotFound,\n",
    "                'stepsFoundByRegex': stepsFoundByRegex,\n",
    "                'asAboveFound': asAboveFound}\n",
    "    \n",
    "    def extractHippocampalSclerosis(self, fileLocation):\n",
    "        with open(fileLocation) as file:\n",
    "            filetext = file.read()\n",
    "        for regex in hippocampalSclerosisRegex:\n",
    "            matches = re.findall(regex, filetext) \n",
    "            if matches:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def lookUpSurgicalResult(self, surgicalPatients, maxHospitalNumbers):\n",
    "        '''\n",
    "        Takes the MRN associated with this xml file, and looks it up in a DF of surgical patients supplied by\n",
    "        surgicalPatients.\n",
    "        If the record exists (ie this patient has had surgery), self._hadSurgery = True.\n",
    "        If hadSurgery = True, look up which zone was removed (eg T Lx), and if the patient was Entirely Seizure\n",
    "        Free (boolean column in the excel file)\n",
    "        \n",
    "        Returns a dict: hadSurgery = True/False, surgerySuccess = True/False/Na, '''\n",
    "        foundRecord = False\n",
    "        recordNumber = None\n",
    "        for columnNumber in range(maxHospitalNumbers):\n",
    "            columnRecords = np.where(\n",
    "                    (surgicalPatients[columnNumber] == self._dataDict['MRN1']) | (surgicalPatients[columnNumber] == '0'+self._dataDict['MRN1'])\n",
    "                )[0]\n",
    "            if len(columnRecords) == 1 and foundRecord == False:\n",
    "                recordNumber = columnRecords[0]\n",
    "                foundRecord = True\n",
    "            elif len(columnRecords) == 1 and foundRecord == True:\n",
    "                raise ValueError('Multiple MRNs matched')\n",
    "            elif len(columnRecords) > 1  and foundRecord == False: #If multiple records found, choose the latest\n",
    "                print('Found multiple records in surgical DB matching MRN', self._dataDict['MRN1'], '. Choosing latest record.')\n",
    "                recordNumber = columnRecords[-1]\n",
    "                foundRecord = True\n",
    "\n",
    "        if foundRecord:\n",
    "            self._dataDict['Had surgery'] = True\n",
    "            self._dataDict['Entirely Seizure-Free'] = surgicalPatients.loc[recordNumber]['boolean']\n",
    "            self._dataDict['OP Type'] = surgicalPatients.loc[recordNumber]['OP Type']\n",
    "            self._dataDict['OP Date'] = surgicalPatients.loc[recordNumber]['OP Date']\n",
    "            self._dataDict['Side'] = surgicalPatients.loc[recordNumber]['Side']\n",
    "            self._dataDict['IC'] = surgicalPatients.loc[recordNumber]['IC']\n",
    "        else:\n",
    "            self._dataDict['Had surgery'] = False\n",
    "            self._dataDict['Entirely Seizure-Free'] = None\n",
    "            self._dataDict['OP Type'] = None\n",
    "            self._dataDict['OP Date'] = None\n",
    "            self._dataDict['Side'] = None\n",
    "            self._dataDict['IC'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineRemovalLists():\n",
    "    fullRemovalList = []\n",
    "    basicBannedList = [\n",
    "        'sz',\n",
    "        ' >',\n",
    "        '>',  \n",
    "    ]\n",
    "    bracketOnlyBannedList = [\n",
    "        'h',\n",
    "        'vt',\n",
    "        'vtr',\n",
    "        'r',\n",
    "    ]\n",
    "    specialBannedList = [\n",
    "        'h/vt',\n",
    "        'h/vtr',\n",
    "        'vt/h',\n",
    "        'vtr/h',\n",
    "        \n",
    "        'h/vt',\n",
    "        'h/vtr',\n",
    "        'vt/h',\n",
    "        'vtr/h',\n",
    "        \n",
    "        'h /vt',\n",
    "        'h /vtr',\n",
    "        'vt /h',\n",
    "        'vtr /h',\n",
    "        \n",
    "        'h;vt',\n",
    "        'h;vtr',\n",
    "        'vt;h',\n",
    "        'vtr;h',\n",
    "        \n",
    "        'h; vt',\n",
    "        'h; vtr',\n",
    "        'vt; h',\n",
    "        'vtr; h',\n",
    "        \n",
    "        'h,vt',\n",
    "        'h,vtr',\n",
    "        'vt,h',\n",
    "        'vtr,h',\n",
    "        \n",
    "        'h, vt',\n",
    "        'h, vtr',\n",
    "        'vt, h',\n",
    "        'vtr, h',\n",
    "        '',\n",
    "    ]\n",
    "    brackets = [['(', ')'],\n",
    "                ['{', '}'],\n",
    "                ['[', ']'],]\n",
    "    \n",
    "    for stringToRemove in specialBannedList+basicBannedList:\n",
    "        fullRemovalList.append(stringToRemove)\n",
    "        for bracket in brackets:\n",
    "            fullRemovalList.append((bracket[0]+stringToRemove+bracket[1]))\n",
    "    \n",
    "    for stringToRemove in bracketOnlyBannedList:\n",
    "        for bracket in brackets:\n",
    "                fullRemovalList.append((bracket[0]+stringToRemove+bracket[1]))\n",
    "            \n",
    "    return fullRemovalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripClassificationStep(stepText):\n",
    "    stepText = stepText.lower()\n",
    "    for stringToRemove in fullRemovalList:\n",
    "        stepText = stepText.replace(stringToRemove, '')\n",
    "    stepText = stepText.rstrip()\n",
    "    return stepText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineDataLabels():\n",
    "    dataLabels = [\n",
    "        'MRN1',\n",
    "        'MRN2',\n",
    "        'MRN3',\n",
    "        'MRN4',\n",
    "        'IDP',\n",
    "        'Had surgery',\n",
    "        'OP Date',\n",
    "        'OP Type',\n",
    "        'Side',\n",
    "        'IC',\n",
    "        'Entirely Seizure-Free',\n",
    "        'ILAE 1 at 1yr',]\n",
    "    return dataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regexYamlMatch(semiologyRegexDict, textToSearch):\n",
    "    \"\"\"\n",
    "    Goes through multiple keys (and corresponding regular expressions), given as a dict,\n",
    "    and returns a list of keys with matching expressions\n",
    "    \"\"\"\n",
    "    keysFound = []\n",
    "    for semiologyKey, semiologRegexList in semiologyRegexDict.items():\n",
    "        result = False\n",
    "        for semiologyRegex in semiologRegexList:\n",
    "#             if 'LOA' in textToSearch:\n",
    "#             print('Pre-result:', result)\n",
    "#             print('Semiology regex:', semiologyRegex)\n",
    "#             print('Found?:', bool(re.match(semiologyRegex, textToSearch)))\n",
    "            result = result or bool(re.match(semiologyRegex, textToSearch.lower())) or bool(re.match(semiologyRegex, textToSearch)) \n",
    "        if result:\n",
    "            keysFound.append(semiologyKey)\n",
    "    return keysFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenDictionary(dictionary):\n",
    "    final = {}\n",
    "    def _flattenDictionary(dictionary, key=None):\n",
    "        if isinstance(dictionary, dict):\n",
    "            for k, v in dictionary.items():\n",
    "                _flattenDictionary(v, k)\n",
    "        else:\n",
    "            final[key] = dictionary\n",
    "    _flattenDictionary(dictionary)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSurgicalPatientsDf(surgicalPatientRecordPath):\n",
    "    surgicalPatients = pd.read_excel(surgicalPatientRecordPath) #loads a df of patients who have had surgery\n",
    "    splitHospitalNumberDf = surgicalPatients['Hospital No'].str.split(', ', expand=True) #splits hospital numbers, if multiple\n",
    "    numberOfSurgicalRecords, maxHospitalNumbers = splitHospitalNumberDf.shape #maximum number of hospital numbers per user\n",
    "    surgicalPatients = pd.concat([surgicalPatients['Hospital No'].str.split(',', expand=True), surgicalPatients], axis=1)\n",
    "    return surgicalPatients, maxHospitalNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global file paths\n",
    "xmlFolderDirectory = '' #'/Volumes/Encrypted/test_XMLs'\n",
    "surgicalPatientRecordPath = ''\n",
    "pdfToMatlabToMLTranslationPath = ''\n",
    "mlLabelsPath = ''\n",
    "yamlFilePath = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "pdfToMatlabToMLTranslation = pd.read_csv(pdfToMatlabToMLTranslationPath)\n",
    "mlLabels = pd.read_csv(mlLabelsPath, header=None, dtype=str)[0].values\n",
    "with open(yamlFilePath) as f:\n",
    "    yamlFile = yaml.load(f)\n",
    "semiologyRegexDict = flattenDictionary(yamlFile['semiology'])\n",
    "hippocampalSclerosisRegex = yamlFile['Hippocampal Sclerosis']\n",
    "fullRemovalList = defineRemovalLists()\n",
    "dataLabels = defineDataLabels()\n",
    "surgicalPatients, maxHospitalNumbers = extractSurgicalPatientsDf(surgicalPatientRecordPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlObjects = []\n",
    "stepsFound = []\n",
    "stepsNotFound = []\n",
    "stepsFoundByRegex = []\n",
    "asAboveFound = []\n",
    "\n",
    "for filename in log_progress(os.listdir(xmlFolderDirectory)):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        try:\n",
    "            newXmlRecord = XmlRecord(xmlFolderDirectory+\"/\"+filename, surgicalPatients=surgicalPatients, maxHospitalNumbers=maxHospitalNumbers)\n",
    "            xmlRecordDict = newXmlRecord.RawClassificationToChecklists()\n",
    "            xmlObjects.append(newXmlRecord)\n",
    "\n",
    "            stepsFound += xmlRecordDict['stepsFound']\n",
    "            stepsNotFound += xmlRecordDict['stepsNotFound']\n",
    "            stepsFoundByRegex.append(xmlRecordDict['stepsFoundByRegex'])\n",
    "            asAboveFound += xmlRecordDict['asAboveFound']\n",
    "        except:\n",
    "            print('Error in processing file: ', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification steps matched directly: ', len(stepsFound))\n",
    "print('Classification steps found by regex: ', len([i for i in stepsFoundByRegex if i]))\n",
    "print('Classification steps not matched: ', len(stepsNotFound))\n",
    "# print('List of classification steps matched by regex: ', stepsFoundByRegex)\n",
    "# print('List of classification steps not matched: ', stepsNotFound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=range(len(xmlObjects)), columns=dataLabels+list(mlLabels))\n",
    "for index, currentXml in enumerate(xmlObjects):\n",
    "    for dictTitle, dictValue in currentXml._dataDict.items():\n",
    "        df[dictTitle][index] = dictValue\n",
    "    for semiologyTitle, semiologyValue in currentXml._mlFeatureDict.items():\n",
    "        try:\n",
    "            df[semiologyTitle][index] = semiologyValue\n",
    "        except KeyError: #Picks up 'delete'\n",
    "            pass\n",
    "    df['Hippocampal Sclerosis'][index] = currentXml._hippocampalSclerosis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
